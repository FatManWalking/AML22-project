architecture: hgp
batch_size: 200
config: log/hgp/hpt-nci1001
custom_trainer: TrainerDiceLoss
dataset: NCI1
device: cuda
dropout_ratio: 0.002976931479744666
epochs: 60
evaluation_steps: 1
evaluation_strategy: steps
experiment_name: hpt-nci1
experiment_name_suffix: ''
greater_better: true
lamb: 1
load_best: true
log_path: log/hpt-nci1
log_steps: 1
logging: true
logging_strategy: steps
lr: 1e-03
lr_scheduler_type: linear
metric_used: matthews_correlation
nhid: 213
num_classes: 2
num_features: 37
num_workers: 4
output_path: model/hpt-nci1
patience: 100
pooling_ratio: 0.2199001605639263
pruning: true
random_seed: 42
resume_from_checkpoint: false
sample_neighbor: true
save_limits: 5
save_steps: 100
save_strategy: steps
sparse_attention: true
split_ratio: 0.7
structure_learning: true
task_type: graph classification
test_ratio: 0.5
warm_up: 1/5
weight_decay: 1e-03
